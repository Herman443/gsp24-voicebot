<html lang="en">
<head>
    <meta charset="UTF-8">
</head>
<body>
    <div style="width: min-content;">
        <button style="border-radius: 16px; padding-top: 8px; padding-bottom: 8px; padding-left: 24px; padding-right: 24px;" id="startButton">Start Streaming</button>
        <button style="border-radius: 16px; padding-top: 8px; padding-bottom: 8px; padding-left: 24px; padding-right: 24px;" id="stopButton">Stop Streaming</button>
        <br/>
        <br/>
        <div style="margin: 8px;" id="responseContainer"></div>
        <br/>
        <audio src="data:audio" id="audio" controls autoplay></audio>
    </div>
    <script src="https://www.WebRTC-Experiment.com/RecordRTC.js"></script>
    <script>
        var protocol = window.location.protocol === 'http:' ? 'ws' : 'wss';
        let ws = new WebSocket(protocol + '://' + window.location.host + '/web/websocket');
        let mediaRecorder;
        let recorder;
        var timeoutHandle;
        var recorderState = '';
        var isAudioPlaying = false;

        var audio = document.getElementById("audio");
        ws.onmessage = event => {
            if (!(event.data instanceof Blob)) {
                if (event.data == "stop_recording"){
                    recorder.pauseRecording();
                    let responseContainer = document.getElementById('responseContainer');
                    responseContainer.innerHTML += `<b style="font-size: 12px; border-radius: 16px; background-color: #6879D0; color:white; width: fit-content; padding-top: 8px; padding-bottom: 8px; padding-left: 24px; padding-right: 24px;">~~ Paused recording ~~</b>`;
                    return;
                }
                let responseContainer = document.getElementById('responseContainer');
                responseContainer.innerHTML += `<p style="border-radius: 16px; background-color: #6879D0; color:white; width: fit-content; padding-top: 8px; padding-bottom: 8px; padding-left: 24px; padding-right: 24px; right: 0px;">${event.data}</p>`;
				return;				
        	}
 
        	console.log('blob received: ' + event.data.size);
        	blobToBase64(event.data).then(b64 => {
                recorder.pauseRecording();
        		audio.src = "data:audio/x-wav;base64," + b64;
        		console.log(audio.src);
                audio.load();
                audio.play();
                document.getElementById('startButton').disabled = true;
                audio.onloadedmetadata = function() {
                    setTimeout (() => {
                        if (recorderState !== 'pausedByButton') {
                            recorder.resumeRecording();
                            recorderState = '';
                            let responseContainer = document.getElementById('responseContainer');
                            responseContainer.innerHTML += `<b style="font-size: 12px; border-radius: 16px; background-color: #6879D0; color:white; width: fit-content; padding-top: 8px; padding-bottom: 8px; padding-left: 24px; padding-right: 24px;">~~ Recording ~~</b>`;
                        }
                        document.getElementById('startButton').disabled = false;
                    }, audio.duration*1000 + 1500);
                };
        	});
        };

        let handleDataAvailable = (event) => {
            if (event.size > 0) {
                console.log('blob', event)
                blobToBase64(event).then(b64 => {
                    ws.send(b64)
                })
            }
        };

        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.readAsDataURL(blob);
                reader.onload = () => {
                    const base64String = reader.result.split(',')[1];
                    resolve(base64String);
                };
                reader.onerror = (error) => reject(error);
            });
        }

        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                recorder = RecordRTC(stream, {
                    type: 'audio',
                    recorderType: StereoAudioRecorder,
                    mimeType: 'audio/wav',
                    timeSlice: 500,
                    desiredSampRate: 16000,
                    numberOfAudioChannels: 1,
                    ondataavailable: handleDataAvailable
                });

                document.getElementById('startButton').addEventListener('click', () => {
                    if (recorder.state == 'paused') {
                    recorder.resumeRecording();
                    } else {
                        recorder.startRecording();
                    }
                    recorderState = '';
                    let responseContainer = document.getElementById('responseContainer');
                    responseContainer.innerHTML += `<b style="font-size: 12px; border-radius: 16px; background-color: #6879D0; color:white; width: fit-content; padding-top: 8px; padding-bottom: 8px; padding-left: 24px; padding-right: 24px;">~~ Recording ~~</b>`;
                });

                document.getElementById('stopButton').addEventListener('click', () => {
                        recorder.pauseRecording();
                        recorderState = 'pausedByButton';
                        let responseContainer = document.getElementById('responseContainer');
                        responseContainer.innerHTML += `<b style="font-size: 12px; border-radius: 16px; background-color: #6879D0; color:white; width: fit-content; padding-top: 8px; padding-bottom: 8px; padding-left: 24px; padding-right: 24px;">~~ Stopped Recording ~~</b>`;
                });
            });

        ws.onopen = () => {
            console.log('WebSocket connection opened');
        };

        ws.onclose = () => {
            recorder.stopRecording();
            console.log('WebSocket connection closed');
        };
    </script>
</body>
</html>